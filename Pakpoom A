from time import time
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_boston
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

boston = load_boston()
X = boston.data
m = X.shape[0] # number of samples
n = X.shape[1] # number of features
y = boston.target
assert m == y.shape[0]

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)
assert len(X_train) == len(y_train)
assert len(X_test) == len(y_test)

intercept = np.ones((X_train.shape[0], 1))
X_train = np.concatenate((intercept, X_train), axis=1)
intercept = np.ones((X_test.shape[0], 1))
X_test = np.concatenate((intercept, X_test), axis=1)
assert X_train.shape[0] == y_train.shape[0]

class LinearRegression:
       
    def __init__(self, alpha=0.001, max_iteration=1000, 
            loss_old=10000, tolerance=0.00001, method="Batch Gradient"):
        self.alpha = alpha
        self.max_iteration = max_iteration
        self.loss_old = loss_old
        self.tolerance = tolerance
        self.method = method
    
    # for Sto Gradient
    def learning_schedule(self, t):
        t0 = 200 # Please change t0 = any number in case of "Sto Gradient"
        t1 = 1000 # Please change t1 = any number in case of "Sto Gradient"
        return t0 / (t + t1)
    
    def h_theta(self, X):
        return X @ self.theta

    def mse(self, yhat, y):
        return ((yhat - y)**2 / yhat.shape[0]).sum()
    
    def delta_loss(self, loss_new, loss_old, tolerance):
        return np.abs(loss_new - loss_old) < tolerance

    def gradient(self, X, error):
        return X.T @ error      
        
    def fit(self, X, y):
        self.theta = np.zeros(X.shape[1])
        iter_stop = []
        list_of_used_ix = []
        n_epochs = 50
        minibatch_size = 20
        t = 0

        if self.method == "Batch Gradient":
            X_train = X
            y_train = y
        
            for i in range(self.max_iteration):
                
                yhat = self.h_theta(X_train)
                error = yhat - y_train

                # implement early stopping
                # if the absolute difference between old loss vs new loss 
                # does not exceed tolerance, we abort the learning
                loss_new = self.mse(yhat, y_train)
                if self.delta_loss(loss_new, self.loss_old, self.tolerance):  #numpy.allclose
                    iter_stop = i
                    break
                self.loss_old = loss_new
                grad = self.gradient(X_train, error)
                self.theta = self.theta - self.alpha * grad

                iter_stop.append(i)
            print("Stop at iteration: ", iter_stop[-1])

        elif self.method == "Mini-Batch Gradient":
            X_train = X
            y_train = y
            for epoch in range(self.max_iteration):
                shuffled_indices = np.random.permutation(X_train.shape[0])
                X_train_shuffled = X_train[shuffled_indices]
                y_train_shuffled = y_train[shuffled_indices]
                for i in range(0, m, minibatch_size):
                    t += 1
                    X_train = X_train_shuffled[i:i+minibatch_size]
                    y_train = y_train_shuffled[i:i+minibatch_size]
                    
                    yhat = self.h_theta(X_train)
                    error = yhat - y_train

                    # implement early stopping
                    # if the absolute difference between old loss vs new loss 
                    # does not exceed tolerance, we abort the learning
                    loss_new = self.mse(yhat, y_train)
                    if self.delta_loss(loss_new, self.loss_old, self.tolerance):  #numpy.allclose
                        iter_stop = i
                        break
                    self.loss_old = loss_new
                    grad = self.gradient(X_train, error)

                    alpha = self.learning_schedule(epoch*m + i)

                    self.theta = self.theta - alpha * grad

                    iter_stop.append(i)
                    
                print("Stop at iteration: ", iter_stop)                    

        else: # => self.method == "Sto Gradient"
            X_train = X
            y_train = y
            for epoch in range(n_epochs):
                for i in range(X_train.shape[0]):
                    random_index = np.random.randint(X_train.shape[0])
                    X_train = X_train[random_index:random_index+1]
                    y_train = y_train[random_index:random_index+1]
                    
                    yhat = self.h_theta(X_train)
                    error = yhat - y_train

                    # implement early stopping
                    # if the absolute difference between old loss vs new loss 
                    # does not exceed tolerance, we abort the learning
                    loss_new = self.mse(yhat, y_train)
                    if self.delta_loss(loss_new, self.loss_old, self.tolerance):  #numpy.allclose
                        iter_stop = i
                        break
                    self.loss_old = loss_new
                    grad = self.gradient(X_train, error)

                    alpha = self.learning_schedule(epoch*m + i)

                    self.theta = self.theta - alpha * grad

                    iter_stop.append(i)
                    
                print("Stop at iteration: ", iter_stop)
            
# try put method = "Batch Gradient" or "Sto Gradient" or "Mini-Batch Gradient"
model = LinearRegression(method="Mini-Batch Gradient") 
model.fit(X_train, y_train)

# Make prediction
yhat = model.h_theta(X_test)

# Calculate mean squared erroes
mse = model.mse(yhat, y_test)

# print the mse
print("MSE: ", mse)
